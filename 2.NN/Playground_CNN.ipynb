{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beskrivelse\n",
    "Her gives det det samme kode som i Eksemple_CNN.ipynb. Modelen der kunne når et test accuracy på 95%. Her skal vi undersøg om vi kan lave modellen bedre, eller dårligere, og se hvordan at ændre de forskellige parametere har effekt på resultatet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Først importerer vi pakker og overfører datasætet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n",
      "Images shape: (60000, 28, 28)\n",
      "Labels shape: (60000,)\n",
      "Number of classes: 10\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_core as keras\n",
    "from keras_core import layers\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Check shape of images and labels\n",
    "print(\"Images shape:\", x_train.shape)\n",
    "print(\"Labels shape:\", y_train.shape)\n",
    "print(\"Number of classes:\", len(np.unique(y_train)))\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Køre den initial model igen så du kan sammenlign med den senere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opgaver: Undersøg forskellige modeller\n",
    "### Convolution lagene\n",
    "Nu skal du ændre parameter i modellen og se hvis de har en effekt på performance (val_accuracy) og træning hastighed (ms/step). Første prøv at ændre antal af convolution lag. Fjern den første convolution lag og se hvad der sker med validering accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu prøve at fjerne den anden convolution lag istedet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvad hvis du sætter et ekstra convolution lag. Sæt en Conv2D efter den anden MaxPooling2D. Bestem selv parametrene af laget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sammenlign hastighed og accuracy forskel mellem de tre sidste modeller og den basal model. Var de bedre eller dårligere? Hurtigere eller langsomere? Hvorfor tror du det?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling lagene\n",
    "Nu kigger vi på max pooling. Først prøv at fjern alle max pooling lagene og se hvad der sker med hastighed og accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu prøve at set et ekstre max pooling lag før den først convolution lag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvad hvis vi bruger større kerner? Prøv kerne størrelse på (4,4) istedet for (2,2) i de to max pooling lage. Sådan at billederne bliver mindre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sammenlign de sidste tre modeler der bruger forskellige max pooling lag med den initial model. Hvorfor tror du der er forskel i træning hastighed og accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktivering funktionet\n",
    "Aktivering funktionerne er brugt til at gør sikkert at modelen bliver ikke lineart, da en model uden aktivering kan kun finde lineart afhængigheder mellem dataen. Man kan alligevel skift aktivering funktion til en linear funktion ved at bruge strengen \"linear\" istedet for \"relu\". Træn en model der bruger kun linear aktivering i dens convolution lage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der findes også andre ikke lineart funktioner, prøv sigmoid og tanh aktivering funktionerne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sammenlign de forskellige aktiveringsfunktioner. Skal man altid bruge et non-lineart aktiveringsfunktion? Får man hurtigere træning ved at bruge lineart aktivering istedet for ikke lineart aktivering? Er de andre aktivering funktioner så god som RELU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opgave: Undersøg træning parameter\n",
    "Det er ikke kun modellen der er vigtig for at få god resultater. Selve træning processen er også vigtigt.\n",
    "\n",
    "Epochen bestemer hvor langt modellen skal træn, for mange epocher kan resulterer i overfitting, og for færre epocher resulterer i underfitting.\n",
    "\n",
    "Batch størrelsen bestemmer hvor mange data punkter man bruge til at adjusterer vægtene med og hvor mange steps man tager per epoch som bestemmer hvor hurtigt vægtene ændres. Større batches resulterer i mere præcise vægt ændringer, men kan også resultarer i langsommere træning.\n",
    "\n",
    "Der også findes mange forskellige optimering algoritmer der opdaterer vægtene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antal Epocher\n",
    "Nu skal du undersøg om de førrig modeller underfitter. Prøv at øve antal epocher og se hvordan accuracy ændres. Pas på med at gå alt for stort, da flere epocher tager mere tid til at træne prøv at ikke gå over 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Et måde at finde en god epoch mængde er at starte med et stort epoch tal, og så se hvornår validering accuracy starter med at ændrer sig for lidt mellem hvert epoch (fx. 0.1). Dette strategi kaldes for early stopping, og den bruges for at gøre sikker at modellen træner ikke mere end den har bruge for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvad fandt du til at være en god mængde af epocher? Giver det mening at bruge det ekstra tid til at for den mængde øvede accuracy man får? Hvad hvis din model tog 10 minutter eller en time per epoch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersøg træning af vores model\n",
    "Vi har gemt alt statistik fra vores træning under history variablen. Fra den kan vi hente udvikling af vores loss og accuracy igennem træning. Her skal du bruge matplotlib til at lave plotter til at vise udvikling af loss og accuracy. Prøve at se om modellen træner stabilt, eller om der er problemer som over og underfitting ved bruge af de her plotter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss af træning og validering data er givet, lave en matplotlib plot der viser dem:\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy af træning og validering data er givet, lave en matplotlib plot der viser dem:\n",
    "train_accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andre optimering algoritmer\n",
    "Lige nu bruges der SGD som optimering algoritm. Der andre optimizers i keras som kan ses [her](https://keras.io/api/optimizers/) prøv at bruge adam istedet for SGD, som er nyere og er den mest brugt inden for ML lige nu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Var Adam bedre end SGD? Har Adam så mange Epochs som SGD? Brug din plot kode blokke igen for at se om Adam overfitter datasættet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss af træning og validering data er givet, lave en matplotlib plot der viser dem:\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy af træning og validering data er givet, lave en matplotlib plot der viser dem:\n",
    "train_accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opgave: En Sidste Model\n",
    "Nu har du prøvet mange forskellige modeller. Prøv at træne en model med de parametere du tror vil virke bedste og træn det. Når du tror at du har trænet den bedste model, så køre test kodeblokken og se hvor god din model kan detekterer hånd skrevet nummer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VENT!\n",
    "Husk at du skal kun bruge test datasætet en gang til sidste. Er du sikker at din nuværende model er den du vil gerne teste på?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvor meget bedre er denne model end den initial model i Eksemple_CNN.ipynb?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
