{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neurale Netværk med Keras\n",
    "I den næste kode blok er der kodet et simpelt convolutional neurale netværk (CNN) til at genkende tal fra MNISTs håndskrevne tal datasettet. Eksemplet er taget fra [keras hjemmeside](https://keras.io/examples/vision/mnist_convnet/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importering\n",
    "Her importerer vi de pakker vi skal bruge. Keras kan bruge mange forskellige neurale netværk pakker til at virke, vi sætter den op til at bruge pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_core as keras\n",
    "from keras_core import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasæt importering\n",
    "Heldigvis kan man overfør MNIST datasætet ved bruge af et funktion fra keras. Her overfører vi datasætet, hvor den bliver splittet til training og testing splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (60000, 28, 28)\n",
      "Labels shape: (60000,)\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Check shape of images and labels\n",
    "print(\"Images shape:\", x_train.shape)\n",
    "print(\"Labels shape:\", y_train.shape)\n",
    "print(\"Number of classes:\", len(np.unique(y_train)))\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi laver en loop igennem datasætet og viser et billede fra hvert cifre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53293/699801886.py:10: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  Fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fig, ax = plt.subplots(2, 5)\n",
    "label_to_print = 0\n",
    "for img, label in zip(x_train, y_train):\n",
    "    if label == label_to_print:\n",
    "        ax[label_to_print // 5, label_to_print % 5].imshow(img, cmap=\"gray\")\n",
    "        ax[label_to_print // 5, label_to_print % 5].axis(\"off\")\n",
    "        label_to_print += 1\n",
    "    if label_to_print == num_classes:\n",
    "        break\n",
    "Fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derefter vi laver billedernes pixler fra heltal mellem [0,255] til decimaltal mellem [0,1], fordi neurale netværk algoritmerne virker bedre med normaliseret værdier.\n",
    "\n",
    "De sidste to linjer laver billed labels fra nummer til [one-hot encoded](https://www.kaggle.com/code/dansbecker/using-categorical-data-with-one-hot-encoding) vektorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialisering\n",
    "Derafter laver vi CNN modelen som vi skal træne til at genkende talene. Her bruges der kun to convolutional lag til at finde mønstre og en sidste almindelig neurale netværk lag (Dense) til at bruge de der mønstre til at lave sandsynlighed for hvilket nummer billedet er.\n",
    "\n",
    "De convolutional lag bruger RELU som aktivering funktion, og den sidste dense lag bruger softmax fordi dens output vektor skal være en sandsynlighedsvektor.\n",
    "\n",
    "Imellem hver convolutional lag er der en Max Pooling lag, som gør billederne mindre og gør det nemmere at have flere convolution kanaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,010</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)              │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │     \u001b[38;5;34m16,010\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,826</span> (136.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,826\u001b[0m (136.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,826</span> (136.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,826\u001b[0m (136.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model træning\n",
    "Her sætter vi alle de værdier der skal bruges til at træne modellen, og så træner vi den.\n",
    "\n",
    "Først sætter vi vores batch size, som bestemmer hvor mange billeder vi sender igennem modellen før vi tager et weight opdatering step. Derefter vi vælger antal epochs, som bestemmer hvor mange gange vi vil gerne sende hele træning sætet igennem modellen.\n",
    "\n",
    "Under compile metoden vi bestemer loss funktion, optimering algoritmer, og hvordan vi vil gerne mål modellens performance på validering sættet. Vi bruger categorical_crossentropy, som er den mest brugt loss funktion til klassifikation. Vi bruger også simpelt stochastic gradient descent (SGD) til optimering, og procentdel af rigtige klassifikationer til at mål modellens performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.3924 - loss: 1.9386 - val_accuracy: 0.8868 - val_loss: 0.4149\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.8767 - loss: 0.4282 - val_accuracy: 0.9323 - val_loss: 0.2475\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9097 - loss: 0.3086 - val_accuracy: 0.9450 - val_loss: 0.2041\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9265 - loss: 0.2498 - val_accuracy: 0.9558 - val_loss: 0.1657\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9380 - loss: 0.2075 - val_accuracy: 0.9595 - val_loss: 0.1493\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing af Vores Model\n",
    "Til sidst bruger vi de 10 tusind test billeder til at evaluerer hvor god vores trænet model er til at klassifikerer billeder den har ikke set før."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.16550849378108978\n",
      "Test accuracy: 0.9523000121116638\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opgaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentering opgaver findes i Playground_CNN.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
